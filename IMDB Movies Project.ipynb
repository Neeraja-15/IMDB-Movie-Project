{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46cacae3-efc8-4439-8276-7ee325e059e9",
   "metadata": {},
   "source": [
    "# My IMDb Top 250 Movies Scraper Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8528b26-a14d-4d24-a6ab-06ca98d90e2f",
   "metadata": {},
   "source": [
    "# Step 1: Scraping the website and Store Raw Data\n",
    "This step fetches the raw data and saves into a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e70424-ea35-4e86-82ce-8e42c559129f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the page!\n",
      "Raw data saved to 'imdb_raw_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Send a request to IMDb's Top 250 movies page\n",
    "url = \"https://www.imdb.com/chart/top/\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Upgrade-Insecure-Requests': '1'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully fetched the page!\")\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Find all movie entries\n",
    "    movie_table = soup.find('ul', class_='ipc-metadata-list')  # Parent container\n",
    "    movies = []\n",
    "    \n",
    "    for movie in movie_table.select('li.ipc-metadata-list-summary-item'):\n",
    "        # Extract title, removing rank number\n",
    "        title_elem = movie.find('h3', class_='ipc-title__text')\n",
    "        title = title_elem.get_text(strip=True).split('. ', 1)[1] if title_elem else 'N/A'\n",
    "        \n",
    "        # Extract year (first metadata item)\n",
    "        metadata_items = movie.find_all('span', class_='sc-f30335b4-7 jhjEEd cli-title-metadata-item')\n",
    "        year = metadata_items[0].get_text(strip=True) if metadata_items else 'N/A'\n",
    "        \n",
    "        # Extract rating\n",
    "        rating_elem = movie.find('span', class_='ipc-rating-star--rating')\n",
    "        rating = rating_elem.get_text(strip=True) if rating_elem else 'N/A'\n",
    "        \n",
    "        # Append to list\n",
    "        movies.append({\n",
    "            'title': title,\n",
    "            'year': year,\n",
    "            'rating': rating\n",
    "        })\n",
    "    \n",
    "    # Store raw data\n",
    "    df_raw = pd.DataFrame(movies)\n",
    "    df_raw.to_csv('imdb_raw_data.csv', index=False)\n",
    "    print(\"Raw data saved to 'imdb_raw_data.csv'\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ac56b-27cf-446f-9d0c-b71cb5bcbbc7",
   "metadata": {},
   "source": [
    "# Step 2: Generate Initial Data Sample\n",
    "I take the first 5 movies from my raw data to see what I scraped. I print them out and save them to `imdb_raw_sample.csv` so I can check them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef2afae-24fd-41fd-85e3-ec8d67493a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Sample:\n",
      "                      title  year rating\n",
      "0  The Shawshank Redemption  1994    9.3\n",
      "1             The Godfather  1972    9.2\n",
      "2           The Dark Knight  2008    9.0\n",
      "3     The Godfather Part II  1974    9.0\n",
      "4              12 Angry Men  1957    9.0\n",
      "Initial sample saved to 'imdb_raw_sample.csv'\n"
     ]
    }
   ],
   "source": [
    "# Add after storing raw data\n",
    "sample_raw = df_raw.head(5)\n",
    "print(\"Initial Data Sample:\")\n",
    "print(sample_raw)\n",
    "sample_raw.to_csv('imdb_raw_sample.csv', index=False)\n",
    "print(\"Initial sample saved to 'imdb_raw_sample.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad9e34-01a8-4ddd-985d-fee737ec6ea7",
   "metadata": {},
   "source": [
    "# Step 3: Process the Data\n",
    "I make a function to fix the data. It turns the `year` into a number (like \"1994\" to 1994) and the `rating` into a number (like \"9.3\" to 9.3). If something goes wrong, I use 0 or 0.0. Then, I save it to `imdb_processed_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47d4f78-cf75-4507-af5b-69106114e513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to 'imdb_processed_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Data processing function\n",
    "def process_data(df):\n",
    "    # Title is already clean (rank removed during scraping)\n",
    "    # Convert Year to integer, handle 'N/A'\n",
    "    df['year'] = pd.to_numeric(df['year'], errors='coerce').fillna(0).astype(int)\n",
    "    # Rating is already numeric, but ensure float type\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce').fillna(0.0)\n",
    "    return df\n",
    "\n",
    "df_processed = process_data(df_raw.copy())\n",
    "df_processed.to_csv('imdb_processed_data.csv', index=False)\n",
    "print(\"Processed data saved to 'imdb_processed_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81e422-b67b-4175-a3f3-ec6f89e0bab4",
   "metadata": {},
   "source": [
    "# Step 4: Generate Processed Data Sample\n",
    "I show the first 5 movies after processing to make sure the years and ratings are numbers now. I save them to `imdb_processed_sample.csv` too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f5e71c-ef04-4495-a637-fe7464fd4b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Data Sample:\n",
      "                      title  year  rating\n",
      "0  The Shawshank Redemption  1994     9.3\n",
      "1             The Godfather  1972     9.2\n",
      "2           The Dark Knight  2008     9.0\n",
      "3     The Godfather Part II  1974     9.0\n",
      "4              12 Angry Men  1957     9.0\n",
      "Processed sample saved to 'imdb_processed_sample.csv'\n"
     ]
    }
   ],
   "source": [
    "sample_processed = df_processed.head(5)\n",
    "print(\"Processed Data Sample:\")\n",
    "print(sample_processed)\n",
    "sample_processed.to_csv('imdb_processed_sample.csv', index=False)\n",
    "print(\"Processed sample saved to 'imdb_processed_sample.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8b35a-5fb1-45da-a34d-9096cd6b4b27",
   "metadata": {},
   "source": [
    "# Step 5: Clean the Data\n",
    "I clean the data by removing rows with missing titles or ratings, getting rid of duplicates, and keeping only movies with years after 1900. I save this to `imdb_cleaned_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a7c180a-7873-4ba4-822c-76bb9fafd868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'imdb_cleaned_data.csv'\n"
     ]
    }
   ],
   "source": [
    "def clean_data(df):\n",
    "    # Remove rows with missing critical data\n",
    "    df = df.dropna(subset=['title', 'rating'])\n",
    "    # Remove duplicates\n",
    "    df = df.drop_duplicates(subset=['title'])\n",
    "    # Filter out invalid years\n",
    "    df = df[df['year'] > 1900]\n",
    "    return df\n",
    "\n",
    "df_cleaned = clean_data(df_processed.copy())\n",
    "df_cleaned.to_csv('imdb_cleaned_data.csv', index=False)\n",
    "print(\"Cleaned data saved to 'imdb_cleaned_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db32b6e0-00b5-44c1-98b8-de26b22a9df4",
   "metadata": {},
   "source": [
    "# Step 6: Prepare Final Dataset\n",
    "I sort the cleaned data by rating (highest first) to make it like the Top 250 list. I fix the numbering and save it to `imdb_final_data.csv`. Then, I show the top 5 to see the best movies I got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60aaac18-b52c-4a3c-adc4-af9998f4a0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset saved to 'imdb_final_data.csv'\n",
      "Final Data Preview:\n",
      "                      title  year  rating\n",
      "0  The Shawshank Redemption  1994     9.3\n",
      "1             The Godfather  1972     9.2\n",
      "2           The Dark Knight  2008     9.0\n",
      "3     The Godfather Part II  1974     9.0\n",
      "4              12 Angry Men  1957     9.0\n"
     ]
    }
   ],
   "source": [
    "df_final = df_cleaned.sort_values(by='rating', ascending=False)\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "df_final.to_csv('imdb_final_data.csv', index=False)\n",
    "print(\"Final dataset saved to 'imdb_final_data.csv'\")\n",
    "print(\"Final Data Preview:\")\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c122328-d2ca-4740-b998-5167d5f63492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
